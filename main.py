import streamlit as st

# ãƒšãƒ¼ã‚¸è¨­å®šã‚’æœ€åˆã«å®Ÿè¡Œ
st.set_page_config(
    page_title="è‹±èªå­¦ç¿’ã‚¢ãƒ—ãƒª"
)

import os
import time
from time import sleep
from pathlib import Path
from streamlit.components.v1 import html
from openai import OpenAI
from dotenv import load_dotenv
import functions as ft
import constants as ct

# å„ç¨®è¨­å®š
load_dotenv()

# å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
os.makedirs(ct.AUDIO_INPUT_DIR, exist_ok=True)
os.makedirs(ct.AUDIO_OUTPUT_DIR, exist_ok=True)
os.makedirs("images", exist_ok=True)

# ã‚¢ãƒã‚¿ãƒ¼ç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_avatar_path(icon_path):
    """ã‚¢ã‚¤ã‚³ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã®ãƒ‘ã‚¹ã€å­˜åœ¨ã—ãªã„å ´åˆã¯Noneã‚’è¿”ã™"""
    if os.path.exists(icon_path):
        return icon_path
    return None  # Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¢ãƒã‚¿ãƒ¼ã‚’ä½¿ç”¨

# ğŸ¨ ã‚¢ãƒ—ãƒªãƒ˜ãƒƒãƒ€ãƒ¼
st.markdown("""
<div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); 
            padding: 1.5rem; border-radius: 10px; margin-bottom: 2rem;">
    <h1 style="color: white; text-align: center; margin: 0; font-size: 2.5rem;">
        ğŸ“ AIè‹±ä¼šè©±å­¦ç¿’ã‚¢ãƒ—ãƒª
    </h1>
    <p style="color: white; text-align: center; margin: 0.5rem 0 0 0; opacity: 0.9;">
        OpenAI GPTã‚’æ´»ç”¨ã—ãŸéŸ³å£°è‹±ä¼šè©±ç·´ç¿’ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
    </p>
</div>
""", unsafe_allow_html=True)

# åˆæœŸå‡¦ç†
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.start_flg = False
    st.session_state.pre_mode = ""
    st.session_state.shadowing_flg = False
    st.session_state.shadowing_button_flg = False
    st.session_state.shadowing_count = 0
    st.session_state.shadowing_first_flg = True
    st.session_state.shadowing_audio_input_flg = False
    st.session_state.shadowing_evaluation_first_flg = True
    st.session_state.dictation_flg = False
    st.session_state.dictation_button_flg = False
    st.session_state.dictation_count = 0
    st.session_state.dictation_first_flg = True
    st.session_state.dictation_chat_message = ""
    st.session_state.dictation_evaluation_first_flg = True
    st.session_state.chat_open_flg = False
    st.session_state.problem = ""
    
    st.session_state.openai_obj = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’ä½¿ç”¨ï¼ˆlangchainä¸ä½¿ç”¨ï¼‰
    st.session_state.conversation_history = []

    # OpenAI APIã‚’ç›´æ¥ä½¿ç”¨ï¼ˆlangchainä¸ä½¿ç”¨ï¼‰

# ğŸ“Š ã‚µã‚¤ãƒ‰ãƒãƒ¼ - å­¦ç¿’çµ±è¨ˆ
with st.sidebar:
    st.markdown("### ğŸ“Š å­¦ç¿’çµ±è¨ˆ")
    
    # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
    user_messages = [msg for msg in st.session_state.messages if msg["role"] == "user"]
    ai_messages = [msg for msg in st.session_state.messages if msg["role"] == "assistant"]
    
    col_stat1, col_stat2 = st.columns(2)
    with col_stat1:
        st.metric("ğŸ’¬ ä¼šè©±å›æ•°", len(user_messages))
    with col_stat2:
        st.metric("ğŸ¤– AIå¿œç­”", len(ai_messages))
    
    # ç¾åœ¨ã®è¨­å®šè¡¨ç¤º
    st.markdown("### âš™ï¸ ç¾åœ¨ã®è¨­å®š")
    if 'mode' in st.session_state:
        st.write(f"ğŸ“š **ãƒ¢ãƒ¼ãƒ‰**: {st.session_state.mode}")
    if 'speed' in st.session_state:
        st.write(f"ğŸµ **é€Ÿåº¦**: {st.session_state.speed}")
    if 'englv' in st.session_state:
        st.write(f"ğŸ“Š **ãƒ¬ãƒ™ãƒ«**: {st.session_state.englv}")
    
    # ç¿»è¨³è¡¨ç¤ºè¨­å®š
    st.markdown("### ğŸŒ ç¿»è¨³è¨­å®š")
    if 'show_translation' not in st.session_state:
        st.session_state.show_translation = True
    
    st.session_state.show_translation = st.checkbox(
        "ğŸ“– æ—¥æœ¬èªç¿»è¨³ã‚’è¡¨ç¤º", 
        value=st.session_state.show_translation,
        help="è‹±èªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«æ—¥æœ¬èªç¿»è¨³ã‚’è¿½åŠ è¡¨ç¤ºã—ã¾ã™"
    )
    
    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    st.markdown("---")
    if st.button("ğŸ”„ ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
        st.session_state.messages = []
        st.session_state.start_flg = False
        st.session_state.shadowing_flg = False
        st.session_state.dictation_flg = False
        st.session_state.chat_open_flg = False
        st.rerun()

# ğŸ“± ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
st.markdown("### ğŸ¯ å­¦ç¿’è¨­å®š")

# è¨­å®šã‚¨ãƒªã‚¢ã‚’2è¡Œã«åˆ†ã‘ã¦ã‚¹ãƒƒã‚­ãƒªã¨é…ç½®
with st.container():
    # 1è¡Œç›®ï¼šåŸºæœ¬è¨­å®š
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        st.session_state.mode = st.selectbox(
            label="ğŸ“š å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰", 
            options=[ct.MODE_1, ct.MODE_2, ct.MODE_3], 
            label_visibility="visible",
            help="å­¦ç¿’ã—ãŸã„ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
    with col2:
        st.session_state.speed = st.selectbox(
            label="ğŸµ å†ç”Ÿé€Ÿåº¦", 
            options=ct.PLAY_SPEED_OPTION, 
            index=3, 
            label_visibility="visible",
            help="éŸ³å£°ã®å†ç”Ÿé€Ÿåº¦ã‚’èª¿æ•´ã§ãã¾ã™"
        )
    with col3:
        st.session_state.englv = st.selectbox(
            label="ğŸ“Š è‹±èªãƒ¬ãƒ™ãƒ«", 
            options=ct.ENGLISH_LEVEL_OPTION, 
            label_visibility="visible",
            help="ã‚ãªãŸã®è‹±èªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
    
    # 2è¡Œç›®ï¼šé–‹å§‹ãƒœã‚¿ãƒ³
    st.markdown("---")
    col_start = st.columns([1, 2, 1])
    with col_start[1]:
        if st.session_state.start_flg:
            st.button("â¸ï¸ å­¦ç¿’ä¸­...", use_container_width=True, type="secondary", disabled=True)
        else:
            st.session_state.start_flg = st.button("ğŸš€ å­¦ç¿’é–‹å§‹", use_container_width=True, type="primary")
    
    # ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ãŸéš›ã®å‡¦ç†
    if st.session_state.mode != st.session_state.pre_mode:
        # è‡ªå‹•ã§ãã®ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
        st.session_state.start_flg = False
        # ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        if st.session_state.mode == ct.MODE_1:
            st.session_state.dictation_flg = False
            st.session_state.shadowing_flg = False
        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        st.session_state.shadowing_count = 0
        if st.session_state.mode == ct.MODE_2:
            st.session_state.dictation_flg = False
        # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        st.session_state.dictation_count = 0
        if st.session_state.mode == ct.MODE_3:
            st.session_state.shadowing_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã‚’éè¡¨ç¤ºã«ã™ã‚‹
        st.session_state.chat_open_flg = False
    st.session_state.pre_mode = st.session_state.mode

# ğŸ“‹ ã‚¢ãƒ—ãƒªèª¬æ˜ã¨ã‚¬ã‚¤ãƒ‰
st.markdown("---")
with st.expander("ğŸ“– ã‚¢ãƒ—ãƒªã®ä½¿ã„æ–¹", expanded=False):
    st.markdown("**ğŸ¯ ç”ŸæˆAIã«ã‚ˆã‚‹éŸ³å£°è‹±ä¼šè©±ç·´ç¿’ã‚¢ãƒ—ãƒª**")
    st.markdown("ä½•åº¦ã‚‚ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã¦ã€è‹±èªåŠ›ã‚’ã‚¢ãƒƒãƒ—ã•ã›ã¾ã—ã‚‡ã†ï¼")
    
    st.markdown("**ã€æ“ä½œæ–¹æ³•ã€‘**")
    col_help1, col_help2 = st.columns(2)
    with col_help1:
        st.info("""
        **ğŸ“š å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰**
        - **æ—¥å¸¸è‹±ä¼šè©±**ï¼šè‡ªç”±ãªä¼šè©±ç·´ç¿’
        - **ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°**ï¼šéŸ³å£°ã‚’èã„ã¦å¾©å”±
        - **ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³**ï¼šèãå–ã‚Šç·´ç¿’
        """)
    with col_help2:
        st.info("""
        **ğŸµ å†ç”Ÿé€Ÿåº¦**
        - **ã‚†ã£ãã‚Š (0.6x-0.8x)**ï¼šåˆå¿ƒè€…å‘ã‘
        - **æ¨™æº– (1.0x)**ï¼šä¸€èˆ¬çš„ãªé€Ÿåº¦  
        - **é€Ÿã‚ (1.2x-2.0x)**ï¼šä¸Šç´šè€…å‘ã‘
        """)
    
    st.warning("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: éŸ³å£°å…¥åŠ›å¾Œã€5ç§’é–“æ²ˆé»™ã™ã‚‹ã¨è‡ªå‹•çš„ã«å‡¦ç†ãŒé–‹å§‹ã•ã‚Œã¾ã™")

# ğŸ’¬ ä¼šè©±å±¥æ­´
st.markdown("### ğŸ’¬ ä¼šè©±å±¥æ­´")

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã®å ´åˆã®è¡¨ç¤º
if not st.session_state.messages:
    st.info("ğŸŒŸ å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«ä¼šè©±å±¥æ­´ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
else:
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã®ã‚«ã‚¦ãƒ³ãƒˆè¡¨ç¤º
    message_count = len([msg for msg in st.session_state.messages if msg["role"] in ["user", "assistant"]])
    st.caption(f"ğŸ’­ ä¼šè©±æ•°: {message_count // 2}å›")

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ä¸€è¦§è¡¨ç¤º
for message in st.session_state.messages:
    if message["role"] == "assistant":
        with st.chat_message(message["role"], avatar=get_avatar_path(ct.AI_ICON_PATH)):
            if st.session_state.show_translation:
                ft.display_english_with_translation(message["content"], True)
            else:
                st.markdown(message["content"])
    elif message["role"] == "user":
        with st.chat_message(message["role"], avatar=get_avatar_path(ct.USER_ICON_PATH)):
            if st.session_state.show_translation:
                ft.display_english_with_translation(message["content"], True)
            else:
                st.markdown(message["content"])
    else:
        st.divider()

# ğŸ¯ ãƒ¢ãƒ¼ãƒ‰åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
if st.session_state.shadowing_flg or st.session_state.dictation_flg:
    st.markdown("---")
    st.markdown("### ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—")
    
    if st.session_state.shadowing_flg:
        col_shadow = st.columns([1, 2, 1])
        with col_shadow[1]:
            st.session_state.shadowing_button_flg = st.button(
                "ğŸ¤ ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°é–‹å§‹", 
                use_container_width=True, 
                type="primary"
            )
    
    if st.session_state.dictation_flg:
        col_dict = st.columns([1, 2, 1])
        with col_dict[1]:
            st.session_state.dictation_button_flg = st.button(
                "âœï¸ ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹", 
                use_container_width=True, 
                type="primary"
            )

# âœï¸ ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰å…¥åŠ›ã‚¨ãƒªã‚¢
if st.session_state.chat_open_flg:
    st.markdown("---")
    st.markdown("### âœï¸ ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å…¥åŠ›")
    st.info("ğŸ§ AIãŒèª­ã¿ä¸Šã’ãŸéŸ³å£°ã‚’ã€ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆæ¬„ã«æ­£ç¢ºã«å…¥åŠ›ã—ã¦ãã ã•ã„")

# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
if st.session_state.mode == ct.MODE_3:
    st.session_state.dictation_chat_message = st.chat_input("âœï¸ èãå–ã£ãŸè‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")
else:
    st.session_state.dictation_chat_message = st.chat_input("ğŸ“ ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿å…¥åŠ›å¯èƒ½ã§ã™", disabled=True)

if st.session_state.dictation_chat_message and not st.session_state.chat_open_flg:
    st.stop()

# ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
if st.session_state.start_flg:

    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€
    # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ãƒãƒ£ãƒƒãƒˆé€ä¿¡æ™‚
    if st.session_state.mode == ct.MODE_3 and (st.session_state.dictation_button_flg or st.session_state.dictation_count == 0 or st.session_state.dictation_chat_message):
        if st.session_state.dictation_first_flg:
            st.session_state.dictation_first_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ä»¥å¤–
        if not st.session_state.chat_open_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()

            st.session_state.chat_open_flg = True
            st.session_state.dictation_flg = False
            st.rerun()
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ™‚ã®å‡¦ç†
        else:
            # ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰å…¥åŠ›ã•ã‚ŒãŸå ´åˆã«ã®ã¿è©•ä¾¡å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            if not st.session_state.dictation_chat_message:
                st.stop()
            
            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                if st.session_state.show_translation:
                    ft.display_english_with_translation(st.session_state.problem, True)
                else:
                    st.markdown(st.session_state.problem)
            with st.chat_message("user", avatar=ct.USER_ICON_PATH):
                if st.session_state.show_translation:
                    ft.display_english_with_translation(st.session_state.dictation_chat_message, True)
                else:
                    st.markdown(st.session_state.dictation_chat_message)

            # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
            st.session_state.messages.append({"role": "user", "content": st.session_state.dictation_chat_message})
            
            with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=st.session_state.dictation_chat_message
                )
                # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆ
                llm_response_evaluation = ft.generate_response(system_template, "")
            
            # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(llm_response_evaluation)
            st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
            st.session_state.messages.append({"role": "other"})
            
            # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
            st.session_state.dictation_flg = True
            st.session_state.dictation_chat_message = ""
            st.session_state.dictation_count += 1
            st.session_state.chat_open_flg = False

            st.rerun()

    
    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œæ—¥å¸¸è‹±ä¼šè©±ã€
    if st.session_state.mode == ct.MODE_1:
        st.write("### ğŸ¤ éŸ³å£°å…¥åŠ›")
        st.info("è‹±èªã§è©±ã—ã¦AIã¨ä¼šè©±ã—ã¾ã—ã‚‡ã†ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²éŸ³ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’é¸æŠã§ãã¾ã™ã€‚")
        
        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        
        # éŸ³å£°éŒ²éŸ³ãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
        if not ft.record_audio(audio_input_file_path):
            st.stop()  # éŸ³å£°å…¥åŠ›ãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã¯å‡¦ç†ã‚’åœæ­¢

        # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            transcript = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text

        # éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(audio_input_text)

        with st.spinner("å›ç­”ã®éŸ³å£°èª­ã¿ä¸Šã’æº–å‚™ä¸­..."):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’LLMã«æ¸¡ã—ã¦å›ç­”å–å¾—ï¼ˆOpenAI APIç›´æ¥ä½¿ç”¨ï¼‰
            llm_response = ft.generate_response(
                ct.SYSTEM_TEMPLATE_BASIC_CONVERSATION, 
                audio_input_text,
                st.session_state.conversation_history
            )
            
            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            st.session_state.conversation_history.extend([
                {"role": "user", "content": audio_input_text},
                {"role": "assistant", "content": llm_response}
            ])
            
            # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            llm_response_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=llm_response
            )

            # ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
            ft.save_to_wav(llm_response_audio.content, audio_output_file_path)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        ft.play_wav(audio_output_file_path, speed=ft.extract_speed_value(st.session_state.speed))

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            if st.session_state.show_translation:
                ft.display_english_with_translation(llm_response, True)
            else:
                st.markdown(llm_response)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã¨LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": audio_input_text})
        st.session_state.messages.append({"role": "assistant", "content": llm_response})


    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€
    # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚
    if st.session_state.mode == ct.MODE_2 and (st.session_state.shadowing_button_flg or st.session_state.shadowing_count == 0 or st.session_state.shadowing_audio_input_flg):
        if st.session_state.shadowing_first_flg:
            st.session_state.shadowing_first_flg = False
        
        if not st.session_state.shadowing_audio_input_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()

        # éŸ³å£°å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.write("### ğŸ¤ éŸ³å£°å…¥åŠ›")
        mode_text = "ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°" if st.session_state.mode == ct.MODE_2 else "ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"
        st.info(f"{mode_text}ç·´ç¿’ï¼šèã„ãŸè‹±èªã‚’æ­£ç¢ºã«ç™ºéŸ³ã—ã¦ãã ã•ã„ã€‚")
        
        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        st.session_state.shadowing_audio_input_flg = True
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        
        # éŸ³å£°éŒ²éŸ³ãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
        if not ft.record_audio(audio_input_file_path):
            st.session_state.shadowing_audio_input_flg = False
            st.stop()  # éŸ³å£°å…¥åŠ›ãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã¯å‡¦ç†ã‚’åœæ­¢
            
        st.session_state.shadowing_audio_input_flg = False

        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            transcript = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            if st.session_state.show_translation:
                ft.display_english_with_translation(st.session_state.problem, True)
            else:
                st.markdown(st.session_state.problem)
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            if st.session_state.show_translation:
                ft.display_english_with_translation(audio_input_text, True)
            else:
                st.markdown(audio_input_text)
        
        # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨éŸ³å£°å…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
        st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
        st.session_state.messages.append({"role": "user", "content": audio_input_text})

        with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
            if st.session_state.shadowing_evaluation_first_flg:
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=audio_input_text
                )
                st.session_state.shadowing_evaluation_first_flg = False
            # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆ
            llm_response_evaluation = ft.generate_response(system_template, "")
        
        # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response_evaluation)
        st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
        st.session_state.messages.append({"role": "other"})
        
        # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
        st.session_state.shadowing_flg = True
        st.session_state.shadowing_count += 1

        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«å†æç”»
        st.rerun()